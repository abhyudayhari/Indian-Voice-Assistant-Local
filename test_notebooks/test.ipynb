{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!git clone https://github.com/AI4Bharat/IndicTrans2.git\n",
    "%%capture\n",
    "%cd IndicTrans2/huggingface_interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nemo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnemo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masr\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnemo_asr\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nemo'"
     ]
    }
   ],
   "source": [
    "\n",
    "import nemo.collections.asr as nemo_asr\n",
    "import os\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TOKEN_OFFSET = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if torch.cuda.is_available() and hasattr(torch.cuda, 'amp') and hasattr(torch.cuda.amp, 'autocast'):\n",
    "    autocast = torch.cuda.amp.autocast\n",
    "else:\n",
    "    @contextlib.contextmanager\n",
    "    def autocast():\n",
    "        yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model(model_path):\n",
    "    asr_model = nemo_asr.models.EncDecCTCModelBPE.restore_from(model_path)\n",
    "    asr_model.eval()\n",
    "    asr_model.to(device='cuda')\n",
    "    return asr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(wav_file, logprobs=False):\n",
    "   \n",
    "    if type(wav_file) != list:\n",
    "        wav_file = [wav_file]\n",
    "    \n",
    "    with autocast():\n",
    "        with torch.no_grad():\n",
    "                return asr_model.transcribe(wav_file)#, logprobs=logprobs)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-07-10 14:14:44 mixins:173] Tokenizer SentencePieceTokenizer initialized with 128 tokens\n",
      "[NeMo I 2024-07-10 14:14:46 mixins:173] Tokenizer SentencePieceTokenizer initialized with 128 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo E 2024-07-10 14:14:46 common:529] Model instantiation failed!\n",
      "    Target class:\tnemo.collections.asr.models.ctc_bpe_models.EncDecCTCModelBPE\n",
      "    Error(s):\tCUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.\n",
      "    Traceback (most recent call last):\n",
      "      File \"/home/abhyuday/Desktop/Mini Project/NeMo/nemo/core/classes/common.py\", line 508, in from_config_dict\n",
      "        instance = imported_cls(cfg=config, trainer=trainer)\n",
      "      File \"/home/abhyuday/Desktop/Mini Project/NeMo/nemo/collections/asr/models/ctc_bpe_models.py\", line 75, in __init__\n",
      "        super().__init__(cfg=cfg, trainer=trainer)\n",
      "      File \"/home/abhyuday/Desktop/Mini Project/NeMo/nemo/collections/asr/models/ctc_models.py\", line 60, in __init__\n",
      "        super().__init__(cfg=cfg, trainer=trainer)\n",
      "      File \"/home/abhyuday/Desktop/Mini Project/NeMo/nemo/core/classes/modelPT.py\", line 147, in __init__\n",
      "        if torch.cuda.is_available() and torch.cuda.current_device() is not None:\n",
      "      File \"/home/abhyuday/miniconda3/envs/abhyuday_env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 778, in current_device\n",
      "        _lazy_init()\n",
      "      File \"/home/abhyuday/miniconda3/envs/abhyuday_env/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
      "        torch._C._cuda_init()\n",
      "    RuntimeError: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.\n",
      "    \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m asr_model\u001b[38;5;241m=\u001b[39m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/abhyuday/Desktop/Mini Project/Models/Kannada.nemo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(model_path):\n\u001b[0;32m----> 2\u001b[0m     asr_model \u001b[38;5;241m=\u001b[39m \u001b[43mnemo_asr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEncDecCTCModelBPE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     asr_model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      4\u001b[0m     asr_model\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Mini Project/NeMo/nemo/core/classes/modelPT.py:468\u001b[0m, in \u001b[0;36mModelPT.restore_from\u001b[0;34m(cls, restore_path, override_config_path, map_location, strict, return_config, save_restore_connector, trainer, validate_access_integrity)\u001b[0m\n\u001b[1;32m    465\u001b[0m app_state\u001b[38;5;241m.\u001b[39mmodel_restore_path \u001b[38;5;241m=\u001b[39m restore_path\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_save_restore_connector(save_restore_connector)\n\u001b[0;32m--> 468\u001b[0m instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_restore_connector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_from\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrestore_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverride_config_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_access_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(instance, ModelPT):\n\u001b[1;32m    479\u001b[0m     instance\u001b[38;5;241m.\u001b[39m_save_restore_connector \u001b[38;5;241m=\u001b[39m save_restore_connector\n",
      "File \u001b[0;32m~/Desktop/Mini Project/NeMo/nemo/core/connectors/save_restore_connector.py:257\u001b[0m, in \u001b[0;36mSaveRestoreConnector.restore_from\u001b[0;34m(self, calling_cls, restore_path, override_config_path, map_location, strict, return_config, trainer, validate_access_integrity)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03mRestores model instance (weights and configuration) into .nemo file\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03m    An instance of type cls or its underlying config (if return_config is set).\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# Get path where the command is executed - the artifacts will be \"retrieved\" there\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# (original .nemo behavior)\u001b[39;00m\n\u001b[0;32m--> 257\u001b[0m loaded_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_config_and_state_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcalling_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrestore_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverride_config_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_access_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loaded_params, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m return_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loaded_params\n",
      "File \u001b[0;32m~/Desktop/Mini Project/NeMo/nemo/core/connectors/save_restore_connector.py:179\u001b[0m, in \u001b[0;36mSaveRestoreConnector.load_config_and_state_dict\u001b[0;34m(self, calling_cls, restore_path, override_config_path, map_location, strict, return_config, trainer, validate_access_integrity)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# get the class\u001b[39;00m\n\u001b[1;32m    178\u001b[0m calling_cls\u001b[38;5;241m.\u001b[39m_set_model_restore_state(is_being_restored\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, folder\u001b[38;5;241m=\u001b[39mtmpdir)\n\u001b[0;32m--> 179\u001b[0m instance \u001b[38;5;241m=\u001b[39m \u001b[43mcalling_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m instance \u001b[38;5;241m=\u001b[39m instance\u001b[38;5;241m.\u001b[39mto(map_location)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# add load_state_dict override\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Mini Project/NeMo/nemo/core/classes/common.py:530\u001b[0m, in \u001b[0;36mSerialization.from_config_dict\u001b[0;34m(cls, config, trainer)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m prev_error:\n\u001b[1;32m    529\u001b[0m                 logging\u001b[38;5;241m.\u001b[39merror(prev_error)\n\u001b[0;32m--> 530\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(instance, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cfg\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    533\u001b[0m     instance\u001b[38;5;241m.\u001b[39m_cfg \u001b[38;5;241m=\u001b[39m config\n",
      "File \u001b[0;32m~/Desktop/Mini Project/NeMo/nemo/core/classes/common.py:522\u001b[0m, in \u001b[0;36mSerialization.from_config_dict\u001b[0;34m(cls, config, trainer)\u001b[0m\n\u001b[1;32m    520\u001b[0m accepts_trainer \u001b[38;5;241m=\u001b[39m Serialization\u001b[38;5;241m.\u001b[39m_inspect_signature_for_trainer(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accepts_trainer:\n\u001b[0;32m--> 522\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    524\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(cfg\u001b[38;5;241m=\u001b[39mconfig)\n",
      "File \u001b[0;32m~/Desktop/Mini Project/NeMo/nemo/collections/asr/models/ctc_bpe_models.py:75\u001b[0m, in \u001b[0;36mEncDecCTCModelBPE.__init__\u001b[0;34m(self, cfg, trainer)\u001b[0m\n\u001b[1;32m     68\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mReplacing placeholder number of classes (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) with actual number of classes - \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     70\u001b[0m             num_classes, \u001b[38;5;28mlen\u001b[39m(vocabulary)\n\u001b[1;32m     71\u001b[0m         )\n\u001b[1;32m     72\u001b[0m     )\n\u001b[1;32m     73\u001b[0m     cfg\u001b[38;5;241m.\u001b[39mdecoder[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_classes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(vocabulary)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Setup decoding objects\u001b[39;00m\n\u001b[1;32m     78\u001b[0m decoding_cfg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoding\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/Mini Project/NeMo/nemo/collections/asr/models/ctc_models.py:60\u001b[0m, in \u001b[0;36mEncDecCTCModel.__init__\u001b[0;34m(self, cfg, trainer)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld_size \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessor \u001b[38;5;241m=\u001b[39m EncDecCTCModel\u001b[38;5;241m.\u001b[39mfrom_config_dict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cfg\u001b[38;5;241m.\u001b[39mpreprocessor)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m EncDecCTCModel\u001b[38;5;241m.\u001b[39mfrom_config_dict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cfg\u001b[38;5;241m.\u001b[39mencoder)\n",
      "File \u001b[0;32m~/Desktop/Mini Project/NeMo/nemo/core/classes/modelPT.py:147\u001b[0m, in \u001b[0;36mModelPT.__init__\u001b[0;34m(self, cfg, trainer)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_model_guid()\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Set device_id in AppState\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     app_state\u001b[38;5;241m.\u001b[39mdevice_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mcurrent_device()\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cfg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_model_being_restored():\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# Setup data loaders now (default) or defer setup to `self.setup()`\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# if `defer_setup` is set in the config of the corresponding dataloader.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/abhyuday_env/lib/python3.10/site-packages/torch/cuda/__init__.py:778\u001b[0m, in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurrent_device\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    777\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getDevice()\n",
      "File \u001b[0;32m~/miniconda3/envs/abhyuday_env/lib/python3.10/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    292\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 293\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    297\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "asr_model=load_model('/home/abhyuday/Desktop/Mini Project/Models/Kannada.nemo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhyuday/miniconda3/envs/miniproj/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, BitsAndBytesConfig\n",
    "from IndicTransTokenizer import IndicProcessor, IndicTransTokenizer\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "quantization = \"4-bit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model_and_tokenizer(ckpt_dir, direction, quantization):\n",
    "    if quantization == \"4-bit\":\n",
    "        qconfig = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        )\n",
    "    elif quantization == \"8-bit\":\n",
    "        qconfig = BitsAndBytesConfig(\n",
    "            load_in_8bit=True,\n",
    "            bnb_8bit_use_double_quant=True,\n",
    "            bnb_8bit_compute_dtype=torch.bfloat16,\n",
    "        )\n",
    "    else:\n",
    "        qconfig = None\n",
    "\n",
    "    tokenizer = IndicTransTokenizer(direction=direction)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        ckpt_dir,\n",
    "        trust_remote_code=True,\n",
    "        low_cpu_mem_usage=True,\n",
    "        quantization_config=qconfig,\n",
    "    )\n",
    "\n",
    "    if qconfig == None:\n",
    "        model = model.to(DEVICE)\n",
    "        if DEVICE == \"cuda\":\n",
    "            model.half()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    return tokenizer, model\n",
    "\n",
    "\n",
    "def batch_translate(input_sentences, src_lang, tgt_lang, model, tokenizer, ip):\n",
    "    translations = []\n",
    "    for i in range(0, len(input_sentences), BATCH_SIZE):\n",
    "        batch = input_sentences[i : i + BATCH_SIZE]\n",
    "\n",
    "        # Preprocess the batch and extract entity mappings\n",
    "        batch = ip.preprocess_batch(batch, src_lang=src_lang, tgt_lang=tgt_lang)\n",
    "\n",
    "        # Tokenize the batch and generate input encodings\n",
    "        inputs = tokenizer(\n",
    "            batch,\n",
    "            src=True,\n",
    "            truncation=True,\n",
    "            padding=\"longest\",\n",
    "            return_tensors=\"pt\",\n",
    "            return_attention_mask=True,\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        # Generate translations using the model\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = model.generate(\n",
    "                **inputs,\n",
    "                use_cache=True,\n",
    "                min_length=0,\n",
    "                max_length=256,\n",
    "                num_beams=5,\n",
    "                num_return_sequences=1,\n",
    "            )\n",
    "\n",
    "        # Decode the generated tokens into text\n",
    "        generated_tokens = tokenizer.batch_decode(generated_tokens.detach().cpu().tolist(), src=False)\n",
    "\n",
    "        # Postprocess the translations, including entity replacement\n",
    "        translations += ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
    "\n",
    "        del inputs\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3267/2021851695.py:17: DeprecationWarning: This IndicTransTokenizer is deprecated.\n",
      "The official Tokenizer is available on HF and can be used as follows:\n",
      "```\n",
      "from transformers import AutoTokenizer\n",
      "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
      "```\n",
      "  tokenizer = IndicTransTokenizer(direction=direction)\n",
      "/tmp/ipykernel_3267/2021851695.py:17: DeprecationWarning: This IndicTransTokenizer is deprecated.\n",
      "The official Tokenizer is available on HF and can be used as follows:\n",
      "```\n",
      "from transformers import AutoTokenizer\n",
      "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
      "```\n",
      "  tokenizer = IndicTransTokenizer(direction=direction)\n"
     ]
    }
   ],
   "source": [
    "indic_en_ckpt_dir =  \"ai4bharat/indictrans2-indic-en-dist-200M\" # \"ai4bharat/indictrans2-indic-en-1B\" \n",
    "indic_en_tokenizer, indic_en_model = initialize_model_and_tokenizer(indic_en_ckpt_dir, \"indic-en\", quantization=quantization)\n",
    "ip = IndicProcessor(inference=True)\n",
    "en_indic_ckpt_dir =   \"ai4bharat/indictrans2-en-indic-dist-200M\"\n",
    "en_indic_tokenizer, en_indic_model = initialize_model_and_tokenizer(en_indic_ckpt_dir, \"en-indic\", quantization)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_lang,tgt_lang=\"kan_Knda\",\"eng_Latn\"\n",
    "src_lang1,tgt_lang1=\"eng_Latn\",\"kan_Knda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"Give very short answers as u are a voice assistant \\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What do you do? Where do you come from? Where do you go?']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_translate(prompt+transcribe(\"/home/abhyuday/Desktop/Mini Project/test_kannada.mp4\"),src_lang,tgt_lang,indic_en_model, indic_en_tokenizer, ip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What do you do? Where do you come from? Where do you go?']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-1.5-flash')"
   ]
  },
,
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=model.generate_content(\"What is the meaning of life?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in response:\n",
    "  print(chunk.text)\n",
    "  print(\"_\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The meaning of life is a question that has been pondered by philosophers, theologians, and individuals for centuries. There is no single, universally accepted answer, as the meaning of life is a deeply personal and subjective experience. Here are some different perspectives:Philosophical perspectives:* Nihilism: This view suggests that life has no inherent meaning or purpose.* Existentialism: This philosophy emphasizes individual freedom and responsibility, suggesting that each person creates their own meaning through their choices and actions.* Hedonism: This view prioritizes pleasure and happiness as the ultimate goal of life.* Utilitarianism: This ethical system focuses on maximizing happiness for the greatest number of people.Religious perspectives:* Monotheistic religions (Christianity, Islam, Judaism): These religions often view life as having a divine purpose, with meaning found in serving God and following His teachings.* Buddhism: This religion emphasizes the pursuit of enlightenment and liberation from suffering.Personal perspectives:* Meaning through relationships: Many people find meaning in their connections with others, such as family, friends, and romantic partners.* Meaning through work or creativity: Some individuals find meaning in their careers or artistic pursuits.* Meaning through service: Helping others and making a positive impact on the world can provide a sense of purpose.* Meaning through personal growth: The journey of self-discovery and personal development can be deeply fulfilling.Ultimately, the meaning of life is a question each individual must answer for themselves. There is no right or wrong answer, and the answer may change throughout a person's life. It's important to remember that:* There is no one-size-fits-all answer. What gives one person meaning may not give another the same sense of purpose.* Meaning can be found in many different places. It's not limited to one specific area of life.* The meaning of life is not static. It can evolve and change over time as our experiences and priorities shift.It is up to each individual to explore their own values, beliefs, and experiences to discover what gives their life meaning. \""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.replace(\"\\n\",\"\").replace(\"**\",\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/abhyuday/Desktop/Mini Project/kannadatest.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m, in \u001b[0;36mtranscribe\u001b[0;34m(wav_file, logprobs)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast():\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 8\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masr_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Mini Project/NeMo/nemo/collections/asr/models/ctc_models.py:158\u001b[0m, in \u001b[0;36mEncDecCTCModel.transcribe\u001b[0;34m(self, audio, batch_size, return_hypotheses, num_workers, channel_selector, augmentor, verbose, override_config)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranscribe\u001b[39m(\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    123\u001b[0m     audio: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m], torch\u001b[38;5;241m.\u001b[39mTensor, np\u001b[38;5;241m.\u001b[39mndarray, DataLoader],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m     override_config: Optional[TranscribeConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    131\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TranscriptionReturnType:\n\u001b[1;32m    132\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    If modify this function, please remember update transcribe_partial_audio() in\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    nemo/collections/asr/parts/utils/trancribe_utils.py\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m        A list of transcriptions (or raw log probabilities if logprobs is True) in the same order as paths2audio_files\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43maudio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_hypotheses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_hypotheses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchannel_selector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannel_selector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43maugmentor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugmentor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/abhyuday_env/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Mini Project/NeMo/nemo/collections/asr/parts/mixins/transcription.py:274\u001b[0m, in \u001b[0;36mTranscriptionMixin.transcribe\u001b[0;34m(self, audio, batch_size, return_hypotheses, num_workers, channel_selector, augmentor, verbose, override_config, **config_kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m     generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranscribe_generator(audio, override_config\u001b[38;5;241m=\u001b[39mtranscribe_cfg)\n\u001b[0;32m--> 274\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m processed_outputs \u001b[38;5;129;01min\u001b[39;00m generator:\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;66;03m# Store results\u001b[39;00m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;66;03m# Create a results of the same type as each element in processed_outputs\u001b[39;00m\n\u001b[1;32m    278\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Mini Project/NeMo/nemo/collections/asr/parts/mixins/transcription.py:382\u001b[0m, in \u001b[0;36mTranscriptionMixin.transcribe_generator\u001b[0;34m(self, audio, override_config)\u001b[0m\n\u001b[1;32m    378\u001b[0m     verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_batch \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranscribing\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m verbose):\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;66;03m# Move batch to device\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m     test_batch \u001b[38;5;241m=\u001b[39m \u001b[43mmove_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranscribe_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;66;03m# Run forward pass\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transcribe_forward(test_batch, transcribe_cfg)\n",
      "File \u001b[0;32m~/Desktop/Mini Project/NeMo/nemo/collections/asr/parts/mixins/transcription.py:76\u001b[0m, in \u001b[0;36mmove_to_device\u001b[0;34m(batch, device, non_blocking)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39mnon_blocking)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [move_to_device(x, device, non_blocking) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: move_to_device(v, device, non_blocking) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/Desktop/Mini Project/NeMo/nemo/collections/asr/parts/mixins/transcription.py:76\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39mnon_blocking)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mmove_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: move_to_device(v, device, non_blocking) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/Desktop/Mini Project/NeMo/nemo/collections/asr/parts/mixins/transcription.py:74\u001b[0m, in \u001b[0;36mmove_to_device\u001b[0;34m(batch, device, non_blocking)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03mRecursively move all tensors in `batch` to `device`.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [move_to_device(x, device, non_blocking) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m batch]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "transcribe(\"/home/abhyuday/Desktop/Mini Project/kannadatest.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ಅದು ದೊಡ್ಡ ಪ್ರಶ್ನೆಯಾಗಿದೆ! ಪ್ರತಿಯೊಬ್ಬರೂ ತಮ್ಮ ಜೀವನಕ್ಕೆ ಏನು ಅರ್ಥ ನೀಡುತ್ತದೆ ಎಂಬುದನ್ನು ನಿರ್ಧರಿಸುತ್ತಾರೆ.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp=str(batch_translate(transcribe(\"/home/abhyuday/Desktop/Mini Project/kannadatest.mp4\"),src_lang,tgt_lang,indic_en_model, indic_en_tokenizer, ip)[0])\n",
    "print(inp)\n",
    "inp=str(model.generate_content(prompt+\"What is the meaning of life\").text).replace(\"**\",\"\").replace('*',\"\").replace(\".\",\"\").split(\".\")\n",
    "#eng_Latn\",\"kan_Knda\"\n",
    "hi_translations = \"\".join(batch_translate(inp, \"eng_Latn\",\"kan_Knda\",en_indic_model , en_indic_tokenizer, ip))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"That's a big question!  There's no one answer, it's up to each person to find their own meaning \\n\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_translate(inp,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "from TTS.utils.synthesizer import Synthesizer\n",
    "from Indic_TTS.inference.src.inference import TextToSpeechEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Using model: fast_pitch\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Init speaker_embedding layer.\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n",
      "Removing weight norm...\n"
     ]
    }
   ],
   "source": [
    "lang = \"kn\"\n",
    "kn_model  = Synthesizer(\n",
    "    tts_checkpoint=f'models/v1/{lang}/fastpitch/best_model.pth',\n",
    "    tts_config_path=f'models/v1/{lang}/fastpitch/config.json',\n",
    "    tts_speakers_file=f'models/v1/{lang}/fastpitch/speakers.pth',\n",
    "    # tts_speakers_file=None,\n",
    "    tts_languages_file=None,\n",
    "    vocoder_checkpoint=f'models/v1/{lang}/hifigan/best_model.pth',\n",
    "    vocoder_config=f'models/v1/{lang}/hifigan/config.json',\n",
    "    encoder_checkpoint=\"\",\n",
    "    encoder_config=\"\",\n",
    "    use_cuda=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "models={\"kn\":kn_model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Multilingual model for transliteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dicts into RAM: 100%|██████████| 1/1 [00:07<00:00,  7.48s/it]\n",
      " NeMo-text-processing :: INFO     :: Creating ClassifyFst grammars.\n",
      "INFO:NeMo-text-processing:Creating ClassifyFst grammars.\n"
     ]
    }
   ],
   "source": [
    "engin=TextToSpeechEngine(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'simpleaudio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msimpleaudio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msa\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'simpleaudio'"
     ]
    }
   ],
   "source": [
    "import simpleaudio as sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['ಅದು ದೊಡ್ಡ ಪ್ರಶ್ನೆಯಾಗಿದೆ!', 'ಪ್ರತಿಯೊಬ್ಬರೂ ತಮ್ಮ ಜೀವನಕ್ಕೆ ಏನು ಅರ್ಥ ನೀಡುತ್ತದೆ ಎಂಬುದನ್ನು ನಿರ್ಧರಿಸುತ್ತಾರೆ.']\n",
      " > Processing time: 3.1996572017669678\n",
      " > Real-time factor: 0.33239315401666686\n"
     ]
    }
   ],
   "source": [
    "kannada_raw_audio = engin.infer_from_text(\n",
    "    input_text=hi_translations,\n",
    "    lang=\"kn\",\n",
    "    speaker_name=\"female\"\n",
    ")\n",
    "DEFAULT_SAMPLING_RATE=16000\n",
    "byte_io = io.BytesIO()\n",
    "scipy.io.wavfile.write(byte_io, DEFAULT_SAMPLING_RATE, kannada_raw_audio)\n",
    "with open(\"kannada_audio1.wav\", \"wb\") as f:\n",
    "    f.write(byte_io.read())\n",
    "\n",
    "# byte_io.seek(0)\n",
    "\n",
    "# # Load the WAV file from the bytes buffer\n",
    "# wav_data = byte_io.read()\n",
    "\n",
    "# # Play the audio data using simpleaudio\n",
    "# play_obj = sa.play_buffer(wav_data, num_channels=1, bytes_per_sample=2, sample_rate=DEFAULT_SAMPLING_RATE)\n",
    "# play_obj.wait_done()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
